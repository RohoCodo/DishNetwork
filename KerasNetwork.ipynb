{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "import random as r\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "178\n592\n"
     ]
    }
   ],
   "source": [
    "def create_input(all_ing, list_ing):\n",
    "    in_layer = []\n",
    "    current = 0\n",
    "    for ing in all_ing:\n",
    "        if ing in list_ing:\n",
    "            in_layer.append(1)\n",
    "        else:\n",
    "            in_layer.append(0)\n",
    "    return in_layer\n",
    "\n",
    "def encode_vals(val, max_val):\n",
    "    out = []\n",
    "    for i in range(max_val + 1):\n",
    "        if i == val:\n",
    "            out.append(1)\n",
    "        else:\n",
    "            out.append(0)\n",
    "    return out\n",
    "\n",
    "categories = ['id', 'cuisine', 'ingredients', 'tp_cat', 'tp_numeric']\n",
    "with open('DishTrain.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "all_ingredients = set()\n",
    "all_ingredients_list = []\n",
    "taste_profile = []\n",
    "one_hot_taste_profile = []\n",
    "ingredient_inputs = []\n",
    "#dish -> taste profile\n",
    "prof_cats = [\"spiciness\", \"oily\", \"saltiness\", \"sweetness\", \"temperature\", \"vegan\", \"vegetarian\"]\n",
    "prof_max = [3, 3, 3, 3, 3, 1, 1]\n",
    "for dishes in data:\n",
    "    for ing in dishes['ingredients']:\n",
    "        all_ingredients.add(ing)\n",
    "\n",
    "for dishes in data:\n",
    "    ingredient_inputs.append(create_input(all_ingredients, dishes['ingredients']))\n",
    "    taste_profile.append(dishes['tp_numeric'])\n",
    "\n",
    "for i in range(len(taste_profile)):\n",
    "    current_encoding = []\n",
    "    for cat in range(7):\n",
    "        current_encoding += encode_vals(taste_profile[i][cat], prof_max[cat])\n",
    "    one_hot_taste_profile.append(current_encoding)\n",
    "\n",
    "all_ingredients_list = list(all_ingredients)\n",
    "print(len(one_hot_taste_profile))\n",
    "print(len(all_ingredients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dishes.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    '''writer.writerow(all_ingredients_list + prof_cats)'''\n",
    "\n",
    "    for i in range(len(ingredient_inputs)):\n",
    "        writer.writerow(ingredient_inputs[i] + one_hot_taste_profile[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = loadtxt('dishes.csv', delimiter=',')\n",
    "dimensions = len(all_ingredients)\n",
    "X = dataframe[:,0:dimensions]\n",
    "y = dataframe[:, dimensions:dimensions+24]\n",
    "sp = y[:, 0:4]\n",
    "oil = y[:, 4:8]\n",
    "salt = y[:, 8:12]\n",
    "sweet = y[:, 12:16]\n",
    "temp = y[:, 16:20]\n",
    "vegan = y[:, 20:22]\n",
    "veget = y[:, 22:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vegan model - 100% accuracy\n",
    "vegan_model = keras.Sequential()\n",
    "vegan_model.add(keras.layers.Dense(dimensions, input_dim=dimensions, activation= 'sigmoid'))\n",
    "vegan_model.add(keras.layers.Dense(dimensions/2, activation= 'relu'))\n",
    "vegan_model.add(keras.layers.Dense(dimensions/4, activation= 'relu'))\n",
    "vegan_model.add(keras.layers.Dense(dimensions/8, activation= 'relu'))\n",
    "vegan_model.add(keras.layers.Dense(dimensions/16, activation= 'relu'))\n",
    "vegan_model.add(keras.layers.Dense(dimensions/32, activation= 'relu'))\n",
    "vegan_model.add(keras.layers.Dense(dimensions/64, activation= 'relu'))\n",
    "vegan_model.add(keras.layers.Dense(dimensions/128, activation= 'relu'))\n",
    "vegan_model.add(keras.layers.Dense(2, activation= 'sigmoid'))\n",
    "vegan_model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# vegetarian model - 100% accuracy\n",
    "vegetarian_model = keras.Sequential()\n",
    "vegetarian_model.add(keras.layers.Dense(dimensions, input_dim=dimensions, activation= 'sigmoid'))\n",
    "vegetarian_model.add(keras.layers.Dense(dimensions/2, activation= 'relu'))\n",
    "vegetarian_model.add(keras.layers.Dense(dimensions/4, activation= 'relu'))\n",
    "vegetarian_model.add(keras.layers.Dense(dimensions/8, activation= 'relu'))\n",
    "vegetarian_model.add(keras.layers.Dense(dimensions/16, activation= 'relu'))\n",
    "vegetarian_model.add(keras.layers.Dense(dimensions/32, activation= 'relu'))\n",
    "vegetarian_model.add(keras.layers.Dense(dimensions/64, activation= 'relu'))\n",
    "vegetarian_model.add(keras.layers.Dense(dimensions/64, activation= 'relu'))\n",
    "vegetarian_model.add(keras.layers.Dense(2, activation= 'sigmoid'))\n",
    "vegetarian_model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# temp model - 100% accuracy\n",
    "temp_model = keras.Sequential()\n",
    "temp_model.add(keras.layers.Dense(dimensions, input_dim=dimensions, activation= 'sigmoid'))\n",
    "temp_model.add(keras.layers.Dense(dimensions/2, activation= 'relu'))\n",
    "temp_model.add(keras.layers.Dense(dimensions/4, activation= 'relu'))\n",
    "temp_model.add(keras.layers.Dense(dimensions/8, activation= 'relu'))\n",
    "temp_model.add(keras.layers.Dense(dimensions/16, activation= 'relu'))\n",
    "temp_model.add(keras.layers.Dense(dimensions/32, activation= 'relu'))\n",
    "temp_model.add(keras.layers.Dense(dimensions/64, activation= 'relu'))\n",
    "temp_model.add(keras.layers.Dense(4, activation= 'sigmoid'))\n",
    "temp_model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# sweet model - 100% accuracy\n",
    "sweet_model = keras.Sequential()\n",
    "sweet_model.add(keras.layers.Dense(dimensions, input_dim=dimensions, activation= 'sigmoid'))\n",
    "sweet_model.add(keras.layers.Dense(dimensions/2, activation= 'relu'))\n",
    "sweet_model.add(keras.layers.Dense(dimensions/4, activation= 'relu'))\n",
    "sweet_model.add(keras.layers.Dense(dimensions/8, activation= 'relu'))\n",
    "sweet_model.add(keras.layers.Dense(dimensions/16, activation= 'relu'))\n",
    "sweet_model.add(keras.layers.Dense(dimensions/32, activation= 'relu'))\n",
    "sweet_model.add(keras.layers.Dense(dimensions/64, activation= 'relu'))\n",
    "sweet_model.add(keras.layers.Dense(4, activation= 'sigmoid'))\n",
    "sweet_model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# salt model - 100% accuracy\n",
    "salt_model = keras.Sequential()\n",
    "salt_model.add(keras.layers.Dense(dimensions, input_dim=dimensions, activation= 'sigmoid'))\n",
    "salt_model.add(keras.layers.Dense(dimensions/2, activation= 'relu'))\n",
    "salt_model.add(keras.layers.Dense(dimensions/4, activation= 'relu'))\n",
    "salt_model.add(keras.layers.Dense(dimensions/8, activation= 'relu'))\n",
    "salt_model.add(keras.layers.Dense(dimensions/16, activation= 'relu'))\n",
    "salt_model.add(keras.layers.Dense(dimensions/32, activation= 'relu'))\n",
    "salt_model.add(keras.layers.Dense(dimensions/64, activation= 'relu'))\n",
    "salt_model.add(keras.layers.Dense(4, activation= 'sigmoid'))\n",
    "salt_model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# oil model - 100% accuracy\n",
    "oil_model = keras.Sequential()\n",
    "oil_model.add(keras.layers.Dense(dimensions, input_dim=dimensions, activation= 'sigmoid'))\n",
    "oil_model.add(keras.layers.Dense(dimensions/2, activation= 'relu'))\n",
    "oil_model.add(keras.layers.Dense(dimensions/4, activation= 'relu'))\n",
    "oil_model.add(keras.layers.Dense(dimensions/8, activation= 'relu'))\n",
    "oil_model.add(keras.layers.Dense(dimensions/16, activation= 'relu'))\n",
    "oil_model.add(keras.layers.Dense(dimensions/32, activation= 'relu'))\n",
    "oil_model.add(keras.layers.Dense(dimensions/64, activation= 'relu'))\n",
    "oil_model.add(keras.layers.Dense(4, activation= 'sigmoid'))\n",
    "oil_model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# spicy model \n",
    "spicy_model = keras.Sequential()\n",
    "spicy_model.add(keras.layers.Dense(dimensions, input_dim=dimensions, activation= 'sigmoid'))\n",
    "spicy_model.add(keras.layers.Dense(dimensions/2, activation= 'relu'))\n",
    "spicy_model.add(keras.layers.Dense(dimensions/4, activation= 'relu'))\n",
    "spicy_model.add(keras.layers.Dense(dimensions/8, activation= 'relu'))\n",
    "spicy_model.add(keras.layers.Dense(dimensions/16, activation= 'relu'))\n",
    "spicy_model.add(keras.layers.Dense(dimensions/32, activation= 'relu'))\n",
    "spicy_model.add(keras.layers.Dense(dimensions/64, activation= 'relu'))\n",
    "spicy_model.add(keras.layers.Dense(4, activation= 'sigmoid'))\n",
    "spicy_model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer='sgd', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.fit(X, vegan, epochs=200, batch_size=10)\n",
    "# _, accuracy = model.evaluate(X, vegan)\n",
    "name = 'vegetarian_binary'\n",
    "def plot_hist(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(name + '_accuracy', dpi=600)\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(name + '_loss', dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "def train(model, output, history_dict, cat):\n",
    "    history_dict[cat] = model.fit(X, output, validation_split=.1, epochs=1000, batch_size=10)\n",
    "    _, accuracy = model.evaluate(X, output)\n",
    "    print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "cats = ['vegan', 'veget', 'temp', 'sweet', 'salt', 'oil', 'sp']\n",
    "small_cat = ['veget']\n",
    "history_dict = {}\n",
    "train(vegetarian_model, veget, history_dict, small_cat[0])\n",
    "'''\n",
    "train(vegetarian_model, veget, history_dict, cats[1])\n",
    "train(temp_model, temp, history_dict, cats[2])\n",
    "train(sweet_model, sweet, history_dict, cats[3])\n",
    "train(salt_model, salt, history_dict, cats[4])\n",
    "train(oil_model, oil, history_dict, cats[5])\n",
    "train(spicy_model, sp, history_dict, cats[6])\n",
    "train(salt_model, salt, history_dict, small_cat[0])\n",
    "train(oil_model, oil, history_dict, small_cat[1])\n",
    "train(spicy_model, sp, history_dict, small_cat[2])'''\n",
    "\n",
    "for label in small_cat:\n",
    "    plot_hist(history_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = sweet_model.predict_classes(X)\n",
    "print(predictions)\n",
    "# summarize the first 5 cases\n",
    "for i in range(len(predictions)):\n",
    "\t    print('%s => %d' % (X[i].tolist(), predictions[i]), *sp[i], sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}